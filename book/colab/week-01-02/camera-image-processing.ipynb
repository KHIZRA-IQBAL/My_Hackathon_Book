{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Camera Image Processing\n",
        "\n",
        "**Learning Objective**: Understand basic computer vision operations for robotics\n",
        "\n",
        "**Estimated Time**: 10 minutes\n",
        "\n",
        "This notebook demonstrates basic image processing that robots perform 30-60 times per second for vision-based control."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install numpy==1.24.0 matplotlib==3.7.0 pillow==9.5.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageFilter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_synthetic_scene() -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Create a synthetic robot vision scene.\n",
        "    \"\"\"\n",
        "    width, height = 640, 480\n",
        "    image = np.ones((height, width, 3), dtype=np.uint8) * 200\n",
        "    \n",
        "    # Add table\n",
        "    image[300:450, 100:540] = [139, 90, 43]\n",
        "    \n",
        "    # Add objects\n",
        "    image[250:300, 150:200] = [220, 50, 50]  # Red cube\n",
        "    image[260:310, 400:450] = [50, 50, 220]  # Blue cylinder\n",
        "    \n",
        "    # Green sphere (center)\n",
        "    center_y, center_x = 280, 320\n",
        "    radius = 30\n",
        "    y, x = np.ogrid[:height, :width]\n",
        "    mask = (x - center_x)**2 + (y - center_y)**2 <= radius**2\n",
        "    image[mask] = [50, 220, 50]\n",
        "    \n",
        "    return image\n",
        "\n",
        "def rgb_to_grayscale(image: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Convert RGB to grayscale using luminosity method.\n",
        "    \"\"\"\n",
        "    return (0.299 * image[:, :, 0] + \n",
        "            0.587 * image[:, :, 1] + \n",
        "            0.114 * image[:, :, 2]).astype(np.uint8)\n",
        "\n",
        "def simple_edge_detection(image: np.ndarray, threshold: int = 30) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Detect edges using gradient-based method.\n",
        "    \"\"\"\n",
        "    pil_img = Image.fromarray(image)\n",
        "    edges_pil = pil_img.filter(ImageFilter.FIND_EDGES)\n",
        "    edges = np.array(edges_pil)\n",
        "    return (edges > threshold).astype(np.uint8) * 255\n",
        "\n",
        "def apply_blur(image: np.ndarray, radius: int = 2) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Apply Gaussian blur to reduce noise.\n",
        "    \"\"\"\n",
        "    pil_img = Image.fromarray(image)\n",
        "    blurred_pil = pil_img.filter(ImageFilter.GaussianBlur(radius=radius))\n",
        "    return np.array(blurred_pil)\n",
        "\n",
        "def calculate_processing_stats(edges: np.ndarray) -> dict:\n",
        "    \"\"\"\n",
        "    Calculate statistics from processed image.\n",
        "    \"\"\"\n",
        "    edge_pixels = np.sum(edges > 0)\n",
        "    total_pixels = edges.size\n",
        "    return {\n",
        "        'edge_pixels': edge_pixels,\n",
        "        'edge_percentage': 100.0 * edge_pixels / total_pixels,\n",
        "        'total_pixels': total_pixels\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and process scene\n",
        "original_image = create_synthetic_scene()\n",
        "grayscale = rgb_to_grayscale(original_image)\n",
        "grayscale_blurred = apply_blur(grayscale, radius=1)\n",
        "edges = simple_edge_detection(grayscale_blurred, threshold=20)\n",
        "\n",
        "# Calculate statistics\n",
        "stats = calculate_processing_stats(edges)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"CAMERA IMAGE PROCESSING: Robot Vision Basics\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nProcessing steps:\")\n",
        "print(\"  1. Capture RGB image (640x480)\")\n",
        "print(\"  2. Convert to grayscale (reduce data)\")\n",
        "print(\"  3. Apply edge detection (find objects)\")\n",
        "print(f\"\\nProcessing Results:\")\n",
        "print(f\"  • Image Resolution: {original_image.shape[1]}x{original_image.shape[0]}\")\n",
        "print(f\"  • Total Pixels: {stats['total_pixels']:,}\")\n",
        "print(f\"  • Edge Pixels Detected: {stats['edge_pixels']:,}\")\n",
        "print(f\"  • Edge Density: {stats['edge_percentage']:.2f}%\")\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"KEY INSIGHT: Robots process images at 30-60 FPS\")\n",
        "print(\"Must be fast and efficient for real-time control!\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize processing pipeline\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "axes[0].imshow(original_image)\n",
        "axes[0].set_title('Original Camera Image\\n(RGB from Intel RealSense)', fontsize=12, fontweight='bold')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(grayscale, cmap='gray')\n",
        "axes[1].set_title('Grayscale Conversion\\n(First preprocessing step)', fontsize=12, fontweight='bold')\n",
        "axes[1].axis('off')\n",
        "\n",
        "axes[2].imshow(edges, cmap='gray')\n",
        "axes[2].set_title('Edge Detection\\n(Object boundaries)', fontsize=12, fontweight='bold')\n",
        "axes[2].axis('off')\n",
        "\n",
        "plt.suptitle('Camera Image Processing Pipeline for Robot Vision', fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Expected Output\n",
        "\n",
        "You should see:\n",
        "1. **Statistics**: 307,200 total pixels, ~5-10% edge pixels\n",
        "2. **Visualization**: Original RGB → Grayscale → Edge map\n",
        "\n",
        "**Key Takeaway**: Robots process camera images continuously for object detection, navigation, and manipulation. Speed and efficiency are critical for real-time control."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
